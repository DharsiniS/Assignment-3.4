1. Explain HDFS federation and High availability

HDFS Federation:

	* HDFS consists of two core layers namely,
		1. Namespace
		2. Block Storage Service

		Namespace:
			* This contains directories, files and blocks.
			* It supports all the namespace related to the file system operations.

		Block Storage Service:
			* This consists of two parts such as 

   1.Block Management- 
		 * This provides data node cluster membership by handling the registeration and peridoic heart beats.
                                     * Processes blocks the reports and maintains location of the blocks.
                                     * It also supports blocks related operations.
                                     * It manages replica placement, block replication and deletes blocks that are over replicated.
   2.Storage -
		* It is provided by datanodes by storing blocks on the local file system and allows read/write access.
		* Prior HDFS architecture,it allows only single namespace for the entire cluster.
		* In that configuration, a single NameNode manages the namespace.
		* HDFS Federation addresses this limitation by adding support for multiple NameNodes or Namespaces to HDFS.

Multiple NameNodes or Namespaces:

	*In order to scale the name service horizonatlly, the federation uses multiple independent Namenodes or Namespaces.
	*Namenodes are federated and are independent,which doesnt require coordination with each other.
	*Datanodes are used for storage by blocks. Each datanode registers with all the namenodes in the cluster.
	*Datanodes send periodic heart beats and block reports.

Block Pool:

	*Its a set of blocks that belongs to a single namespace.
	*Datanodes stores blocks for all the block pools in the cluster.
	*Each block pool is managed independently and this allows namespace to generate block Ids for the new blocks without the need for
  	   coordination with other namespaces.

HDFS High Availability:

	*In the first version of Hadoop, Namenode was a single point of failure in a HDFS cluster.
	*Each cluster had a single NameNode and if the machine becomes unavailable, then the cluster as a whole would be unavailable until the 
 	  NameNode was either restarted or brought up on a separate machine.
                 *This has create an impact on the total availability of the cluster in two major ways:
                      1.In case of unplanned event such as machine crash, the cluster would be unavailable until the operator restarts the NameNode.
                      2.In planned maintenance events such as software or hardware upgrades on namenode machine,it would result in
               cluster downtime.

2. How HDFS handles failures while writing data

*The pipeline is closed and any packets in the ack queue are added to the front of the data queue.
*The current block in the good DataNodes is given a new identity which is communicated to the NameNode.
*The failed DataNode is removed from the pipeline and a new pipeline is constructed from the  good DataNodes.
*The remainder of block's data is under-replicated and it arranges for a further replica to be created on another node.
*As long as dfs.namenode.replication.min replicas are written, the write will succeed.
*The blocks will be asynchronously replicated across the cluster until its target replication factor is reached.